<!DOCTYPE html>
<html lang="en">
  <head>
    <title>Dravyansh Sharma</title>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    
    <link href="https://fonts.googleapis.com/css?family=Poppins:300,400,500,600,700" rel="stylesheet">

    <link rel="stylesheet" href="css/ionicons.min.css">
    <link rel="stylesheet" href="css/style.css">
  </head>
  <body>

	<div id="page">
		<a href="#" class="js-nav-toggle nav-toggle"><i></i></a>
		<aside id="aside" role="complementary" class="js-fullheight text-center">
			<div class="hero-wrap img mb-4" style="background-image: url(images/d.jpg);"></div>

		</aside>
		<div id="main">
			<div class="hero-wrap js-fullheight" data-stellar-background-ratio="0.35">
				<div class="overlay"></div>
				<div class="js-fullheight d-flex justify-content-center align-items-center">
					<div class="col-md-8 text text-center">
						<div class="desc">
							<h1 class="mb-4">Dravyansh Sharma</h1>
							<p class="mb-4">I am currently an <a href="https://www.ttic.edu/postdoc/">IDEAL Postdoc</a> in Chicago. I completed my PhD in the Computer Science Department at the Carnegie Mellon University, and was fortunate to be  
							advised by <a href="https://www.cs.cmu.edu/~ninamf/">Nina Balcan</a>. I am interested in designing
								algorithms for machine learning with strong and provable performance guarantees. <!-- Previously I have worked with the Speech team at <a href="https://about.google/intl/en_us/">Google</a> and completed my 
								undergraduate studies at <a href="http://www.iitd.ac.in/">IIT Delhi</a>. --></p>

<p><a href="#news" class="btn-custom">Recent news </a>
                                                                &nbsp;&nbsp;&nbsp;
  
							<p><a href="#pubs" class="btn-custom">Research </a>
								&nbsp;&nbsp;&nbsp;
								<a href="resume.pdf" class="btn-custom">Résumé <span class="ion-ios-arrow-down"></span></a>
								<!-- &nbsp;&nbsp;&nbsp; -->
								<!-- <a href="#ambi" class="btn-custom">Recherché <span class="ion-ios-arrow-down"></span></a> -->
								&nbsp;&nbsp;&nbsp;
								<a href="#contact" class="btn-custom">Reach me</a>
							</p>
							<p>&nbsp;&nbsp;&nbsp;</p>
							<p>&nbsp;&nbsp;&nbsp;</p>
							<p>&nbsp;&nbsp;&nbsp;</p>
							<p>&nbsp;&nbsp;&nbsp;</p>
							<p>&nbsp;&nbsp;&nbsp;</p>
						</div>
					</div>
				</div>
			</div>
		<section class="ftco-section">
<div class="container" id="news">
                <div class="row justify-content-center mb-5 pb-2">
            <h2 class="mb-i4">Recent News and Highlights</h2>
<ul  style="list-style-type:none;"> 

<li style="color:black;"><b> July 2025 </b></li>

<li>&starf; Attending UAI 2025 in Rio de Janeiro. Come to my in-person <a href="https://www.auai.org/uai2025/tutorials">tutorial</a>! </li>
<li>&starf; Attending ICML 2025 in Vancouver. <a href="https://recorder-v3.slideslive.com/#/share?share=101957&s=fe07876e-b772-4c26-aee6-baa2af6bd1f4">Video</a> of our work.</li>
<li>&starf; Awarded Top Reviewer at UAI 2025.</li>
<li>&bull; New on arxiv <a href="https://arxiv.org/abs/2507.05084">Distribution-dependent Generalization Bounds for Tuning Linear Regression Across Tasks</a> (with Nina Balcan and Saumya Goyal).

<li style="color:black;"><b> June 2025 </b></li>
<li>&starf; My proposal "Limitations of State-of-the-Art and a New Principled Framework for HPO and Algorithm Selection" has been accepted as one of the 2025 AutoML tutorials.
<li>&bull; Gave a talk "Principled Hyperparameter Optimization and Algorithm Selection" at the Capital Area Theory Seminar (CATS) at the University of Maryland, College Park.
<li>&bull; Helped organize <a href="https://www.ideal-institute.org/2025/05/06/ideal-annual-meeting-2025/">IDEAL Annual Meeting</a> (with Lev Reyzin). Gave a talk titled "Principled Hyperparameter Tuning and Algorithm Selection" at the University of Illinois Chicago.</li>
<li>&bull; Five accepted workshop papers (three at ICML 2025, one at IJCAI 2025, one at UAI 2025).</li>
<li>&nbsp;&nbsp;&nbsp;&#11049; ICML 2025 Workshop on Reliable and Responsible Foundation Models (R2-FM)</li>
<li>&nbsp;&nbsp;&nbsp;&#11049; ICML 2025 3rd Workshop on High-dimensional Learning Dynamics (HiLD)</li>
<li>&nbsp;&nbsp;&nbsp;&#11049; ICML 2025 Workshop on 	
Methods and Opportunities at Small Scale (MOSS)</li>
<li>&nbsp;&nbsp;&nbsp;&#11049; IJCAI 2025 2nd Workshop on Social Choice and Learning Algorithms (SCaLA)</li>
<li>&nbsp;&nbsp;&nbsp;&#11049; UAI 2025 Workshop on Safe AI</li>

<li>&bull; New on arxiv <a href="https://arxiv.org/abs/2506.05252">Conservative classifiers do consistently well with improving agents: characterizing statistical and online learning</a> (with Alec Sun).

<li style="color:black;"><b> May 2025 </b></li>
<li>&starf;  Our work <a href="https://arxiv.org/abs/2505.22650">On Learning Verifiers for Chain-of-Thought Reasoning</a> (joint with Nina Balcan, Avrim Blum and Zhiyuan Li) is available as a pre-print.</li>
<li>&starf; New on arxiv <a href="https://arxiv.org/abs/2405.15911">Learning accurate and interpretable tree-based models</a> (joint with Nina Balcan), an extended version of earlier work that won the <a href="https://www.auai.org/uai2024/best_papers">Outstanding Student Paper Award</a> at UAI 2024.</li>
<li>&bull; Presented a poster at the "Midwest Optimization & Statistical Learning Conference 2025" at Northwestern University.</li>
<li>&bull; Our work <i>Tuning Algorithmic and Architectural Hyperparameters in Graph-Based Semi-Supervised Learning with Provable Guarantees</i> (joint with Ally Du and Eric Huang) accepted at UAI 2025.
</li>
<li>&bull;  Our work (joint with Nina Balcan) <i>Learning Accurate and Interpretable Decision Trees (Extended Abstract)</i> accepted at the Best Paper Track for Sister Conferences at IJCAI 2025. 
            </li>
<li>&bull;  Our work <a href="https://arxiv.org/abs/2503.03184">PAC Learning with Improvements</a> (joint with Idan Attias, Avrim Blum, Keziah Naggita, Donya Saless and Matthew Walter) accepted at ICML 2025.
</li>
<li>&bull;  Our paper titled <a href="https://arxiv.org/abs/2409.04367">Algorithm Configuration for Structured Pfaffian Settings</a> (joint with Nina Balcan and Anh Nguyen) published in TMLR 2025.
</li>
<li style="color:black;"><b> April 2025 </b></li>
<li>&bull;  Gave a talk at TTIC on our recent work <i>Provable tuning of deep learning model hyperparameters</i> (joint with Nina Balcan and Anh Nguyen).
</li>
<li>&starf;  My proposal <a href="https://www.auai.org/uai2025/tutorials">Hyperparameter Optimization and Algorithm Selection: Practical Techniques, Theory, and New Frontiers</a> has been accepted as one of the 2025 UAI tutorials. Stay tuned!
</li>
<li>&starf;  Invited to serve as an Area Chair at NeurIPS 2025.
</li>
<li>&bull;  Presented our work <i>Provable tuning of deep learning model hyperparameters</i> (joint with Nina Balcan and Anh Nguyen) at the <a href="https://www.ideal-institute.org/2025/03/07/understanding-the-mechanisms-of-deep-learning-and-generative-modeling/">IDEAL workshop on "Understanding the Mechanisms of Deep Learning and Generative Modeling"</a> at Northwestern University.
</li>
<li>&bull;  Gave a talk titled <i>Provable tuning of deep learning model hyperparameters</i> (based on joint work with Nina Balcan and Anh Nguyen) at the Theory lunch at the University of Chicago.
</li>
<li style="color:black;"><b> March 2025 </b></li>
<li>&starf;  Session Chair at AAAI 2025 sessions on <i>Constraint Satisfaction and Optimization</i>.
</li> 
<li>&bull;  Our work titled <a href="https://arxiv.org/abs/2503.03184">PAC Learning with Improvements</a> (joint with Idan Attias, Avrim Blum, Keziah Naggita, Donya Saless and Matthew Walter) available as a pre-print.
</li>
<li>&bull;  Attending AAAI 2025 in Philly. Presenting <a href="https://arxiv.org/abs/2501.02926">Offline-to-online hyperparameter transfer for stochastic bandits</a>, joint work with Arun Suggala.
</li>
<!--
<li> Feb 2025. Our work titled <a href="https://arxiv.org/abs/2502.12937">Tuning Algorithmic and Architectural Hyperparameters in Graph-Based Semi-Supervised Learning with Provable Guarantees</a> (joint with Ally Du and Eric Huang) is available as a pre-print.
</li>
<li> Jan 2025. Our work titled <a href="https://arxiv.org/abs/2501.13734">Sample complexity of data-driven tuning of model hyperparameters in neural networks with structured parameter-dependent dual function</a> (joint with Nina Balcan and Anh Nguyen) is available as a pre-print.
</li>
<li> Dec 2024. Attended NeurIPS 2024 in Vancouver to present two posters.
</li>
<li> Sep 2024. Started as a postdoc at IDEAL (The Institute for Data, Econometrics, Algorithms, and Learning), part of NSF TRIPODS, hosted by <a href="https://home.ttic.edu/~avrim/">Avrim Blum</a> (TTIC) and <a href="https://users.cs.northwestern.edu/~aravindv/">Aravindan Vijayaraghavan</a> (Northwestern).
</li>
<li> July 2024. Our work (joint with Nina Balcan) <a href="https://arxiv.org/abs/2405.15911">Learning Accurate and Interpretable Decision Trees</a> won the <a href="https://www.auai.org/uai2024/best_papers">Outstanding Student Paper Award</a> at UAI 2024.
</ul>
-->
</div>
</div>
    	<div class="container" id="pubs">
    		<div class="row justify-content-center mb-5 pb-2">
            <h2 class="mb-4">Publications</h2>
            <ul style="list-style-type:none;">
<li><b> 2025 </b></li>
<li> [C20] <a href="https://arxiv.org/abs/2503.03184">PAC Learning with Improvements</a>, ICML 2025</br>
        with <i>Idan Attias</i>, <i>Avrim Blum</i>, <i>Keziah Naggita</i>, <i>Donya Saless</i> and <i>Matthew Walter</i>
</li>
<li> [C19] <a href="https://arxiv.org/abs/2502.12937">Tuning Algorithmic and Architectural Hyperparameters in Graph-Based Semi-Supervised Learning with Provable Guarantees</a>, UAI 2025</br>
        with <i>Ally Yalei Du</i> and <i>Eric Huang</i>
<li> [C18] <a href="https://arxiv.org/abs/2501.02926">Offline-to-online hyperparameter transfer for stochastic bandits</a>, AAAI 2025 </br>
        with <i>Arun Sai Suggala</i>
</li>
<li> [J3] <a href="https://arxiv.org/abs/2409.04367">Algorithm Configuration for Structured Pfaffian Settings</a>, TMLR 2025 </br>
        with <i>Maria-Florina Balcan</i> and <i>Anh Tuan Nguyen</i>
</li>
<li> [A1] <a>Learning Accurate and Interpretable Decision Trees (Extended Abstract)</a>, IJCAI 2025 (Best Papers from Sister Conferences Track)</br>
        with <i>Maria-Florina Balcan</i>
</li>
<li> [A2] <a>An Analysis of Robustness of Non-Lipschitz Networks (Extended Abstract)</a>, Workshop on Safe AI (UAI 2025)</br>
with <i>Maria-Florina Balcan</i>, <i>Avrim Blum</i> and <i>Hongyang Zhang</i>
</li>
<li> [W10] <a>On Learning Verifiers for Chain-of-Thought Reasoning</a>, Workshop on Reliable and Responsible Foundation Models (ICML 2025)</br>
        with <i>Maria-Florina Balcan</i>, <i>Avrim Blum</i> and <i>Zhiyuan Li</i>
</li>
<li> [W9] <a>PAC Learning with Improvements</a>, 2nd Workshop on Social Choice and Learning Algorithms (IJCAI 2025) </br>
        with <i>Idan Attias</i>, <i>Avrim Blum</i>, <i>Keziah Naggita</i>, <i>Donya Saless</i> and <i>Matthew Walter</i>
</li>
<li> [W8] <a>Learning how to step in gradient-based optimization: beyond convexity and smoothness</a>, </br>3rd
Workshop on High-dimensional Learning Dynamics (ICML 2025)</br>
</li>
<li> [W7] <a>Gradient descent in presence of extreme flatness and steepness</a>, </br>Methods and Opportunities
at Small Scale (ICML 2025)</br>
</li>

<li><b> 2024 </b></li>
<li> [T1] CMU CSD PhD Thesis <a href="https://csd-web-01.andrew.cmu.edu/sites/default/files/phd-thesis/CMU-CS-24-120.pdf">Data-driven algorithm design and principled
hyperparameter tuning in machine learning</a>
</li>
<li> [C17] <a href="https://www.jmlr.org/papers/v24/22-0410.html">An Analysis of Robustness of Non-Lipschitz Networks</a>, NeurIPS 2024 (Journal-to-conference track) </br>
	with <i>Maria-Florina Balcan</i>, <i>Avrim Blum</i> and <i>Hongyang Zhang</i>
</li>


<li> [C16]
        <a href="https://openreview.net/forum?id=yW3tlSwusb">Accelerating ERM for data-driven algorithm design using output-sensitive techniques</a>, NeurIPS 2024 </br>
	with <i>Maria-Florina Balcan</i> and <i>Christopher Seiler</i>
</li>

<li> [C15]
        <a href="https://arxiv.org/abs/2409.03129"> Subsidy for repair in component maintenance games</a>, EMI/PMC 2024 </br>
        with <i>Maria-Florina Balcan</i> and <i>Matteo Pozzi</i>
</li>

<li> [C14]
	<a href="https://arxiv.org/abs/2405.15911">Learning Accurate and Interpretable Decision Trees</a>, UAI 2024 (<a style="color:red;">Outstanding student paper award</a>)</br>
	with <i>Maria-Florina Balcan</i>
</li>

<li> [C13]
        <a href="https://ojs.aaai.org/index.php/AAAI/article/view/29412">No Internal Regret with Non-convex Loss Functions</a>, AAAI 2024
</li>
<li> [W6]
        <a>Theoretical Analyses of Hyperparameter Selection in Graph-Based Semi-Supervised Learning</a>, ICML 2024</br>Workshop on Geometry-grounded Representation Learning and Generative Modeling</br>
        with <i>Ally Yalei Du</i> and <i>Eric Huang</i>
</li>

<li> [W5]
	<a> Accelerating data-driven algorithm design using output-sensitive techniques</a>, AAAI 2024</br> Workshop on Learnable Optimization</br>
	with <i>Maria-Florina Balcan</i> and <i>Christopher Seiler</i>
</li>

<li> [W4]
	<a>Shifting regret for tuning combinatorial algorithms with applications to clustering</a>, AAAI 2024</br> Workshop on Learnable Optimization</br>
        with <i>Maria-Florina Balcan</i> and <i>Travis Dick</i>
</li>
<li><b> 2023 </b></li>
<li> [C12]
        <a href="https://openreview.net/pdf?id=8QGukmdAbh">New Bounds for Hyperparameter Tuning of Regression Problems Across Instances</a>, NeurIPS 2023</br>
with <i>Maria-Florina Balcan</i> and <i>Anh Tuan Nguyen</i>
</li>

<li> [C11]
        <a href="https://arxiv.org/abs/2304.03370">Reliable Learning for Test-time Attacks and Distribution Shift</a>, NeurIPS 2023</br>
with <i>Maria-Florina Balcan</i>, <i>Steve Hanneke</i> and <i>Rattana Pukdee</i>
</li>

<li> [C10]
        <a href="https://arxiv.org/abs/2306.07098">Efficiently Learning the Graph for Semi-supervised Learning</a>, UAI 2023</br>
with <i>Maxwell Jones</i>
</li>

<li> [J2]
	<a href="https://arxiv.org/pdf/2010.06154.pdf">An analysis of robustness of non-Lipschitz networks</a>, JMLR 2023 (earlier version in ICLR 2022</br> SRML workshop)</br>
with <i>Maria-Florina Balcan</i>, <i>Avrim Blum</i> and <i>Hongyang Zhang</i>
</li>
<li><b> 2022 </b></li>
<li> [C9]
	<a href="https://arxiv.org/pdf/2207.10199.pdf">Provably tuning the ElasticNet across instances</a>, NeurIPS 2022 [<a href="https://blog.ml.cmu.edu/2024/04/12/how-to-regularize-your-regression/">blog post</a>] </br>
with <i>Maria-Florina Balcan</i>, <i>Mikhail Khodak</i> and <i>Ameet Talwalkar</i>
</li>
<li> [C8]
	<a href="https://arxiv.org/pdf/2203.04160.pdf">Robustly-reliable learners under poisoning attacks</a>, COLT 2022</br>
with <i>Maria-Florina Balcan</i>, <i>Avrim Blum</i> and <i>Steve Hanneke</i>
</li>
<!--<li>
        <a href="https://arxiv.org/pdf/2204.03569.pdf">Faster algorithms for learning to link, align sequences, and price two-part tariffs</a>, Pre-print</br>
with <i>Maria-Florina Balcan</i> and <i>Christopher Seiler</i>
</li>-->
<li> [W3]
	<a href="https://arxiv.org/pdf/2010.06154.pdf">On the Power of Abstention and Data-Driven Decision Making for Adversarial Robustness</a>, ICLR 2022 </br>Workshop on Socially Responsible Machine Learning (<a style="color:red;">Oral</a>)</br>
with <i>Maria-Florina Balcan</i>, <i>Avrim Blum</i> and <i>Hongyang Zhang</i>
</li>
<li><b> 2021 </b></li>
<li> [C7]
	<a href="https://arxiv.org/pdf/2103.10547.pdf">Data driven semi-supervised learning</a>, NeurIPS 2021 (<a style="color:red;">Oral, <1%</a>)</br>
with <i>Maria-Florina Balcan</i>
</li>

<li> [C6]
<a href="https://arxiv.org/pdf/2108.08770.pdf">Learning-to-learn non-convex piecewise-Lipschitz functions</a>, NeurIPS 2021</br>
with <i>Maria-Florina Balcan, Mikhail Khodak, Ameet Talwalkar</i>
</li>


<li> [W2]
<a>Improved pronunciation prediction accuracy using morphology</a>, ACL SIG on Computational Morphology and Phonology (ACL 2021)</br>
with <i>Saumya Sahai, Neha Chaudhari, Antoine Bruguier.</i>
</li>

<li> [W1]
<a>Predicting and Explaining French Grammatical Gender</a>, ACL Special Interest Group (SIG) on Typology (NAACL 2021)</br>
with <i>Saumya Sahai</i>
</li>
<li><b> 2020 and before </b></li>
				<li> [C5]
						<a href="https://arxiv.org/pdf/1907.09137.pdf">Learning Piecewise Lipschitz Functions in Changing Environments</a>, 
						AISTATS 2020 [<a href="shifted-regret-slides.pdf">slides</a>]</br>
						with <i>Maria-Florina Balcan</i> and <i>Travis Dick</i>
				</li>
				<li> [C4]
						<a href="https://www.isca-speech.org/archive/Interspeech_2019/pdfs/3207.pdf">Better morphology prediction for better speech systems</a>, Interspeech 2019</br>
						with <i>Melissa Wilson</i> and <i>Antoine Bruguier</i>
				</li>
				<li> [C3]
						<a href="https://www.isca-speech.org/archive/Interspeech_2018/pdfs/1920.pdf">On Training and Evaluation of Grapheme-to-Phoneme Mappings with Limited Data</a>, Interspeech 2018
				</li>
				<li> [C2]
					<a href="https://www.isca-speech.org/archive/Interspeech_2018/pdfs/2061.pdf">Dictionary Augmented Sequence-to-Sequence Neural Network for Grapheme to Phoneme Prediction</a>, Interspeech 2018</br>
						with <i>Antoine Bruguier</i> and <i>Anton Bakhtin</i>
				</li>
				<li> [J1]
						<a href="https://pdfs.semanticscholar.org/c20c/2628a2e4148ef53a4a8f6550cc451110b027.pdf">Some results on a class of mixed van der Waerden numbers</a>, Rocky Mountain J. Math. 2018</br>
						with <i>Kaushik Maran</i>, <i>Sai Praneeth Reddy</i> and <i>Amitabha Tripathi</i>
				</li>
				<li> [C1]
						<a href="http://proceedings.mlr.press/v37/sharma15.pdf">On greedy maximization of entropy</a>, ICML 2015</br>
						with <i>Amit Deshpande</i> and <i>Ashish Kapoor</i>
				</li>
						<li style="list-style: none">
								<p>&nbsp;&nbsp;&nbsp;</p>
								<p>&nbsp;&nbsp;&nbsp;</p></li>
			</ul>
				
			<div class="col-md-8 text text-center">
			<p><a href="#" class="btn-custom">Home <span class="ion-ios-arrow-up"></span></a></p>
        </div>
	</div>
		</div>
</div>	</div>
<div class="container" id="contact">
                <div class="row justify-content-center mb-5 pb-2">
            <h2 class="mb-4">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Contact: &nbsp;&nbsp;&nbsp;</h2>
E-mail: dravy [AT] ttic [DOT] edu</br>
Office: 434, Toyota Technological Institute at Chicago, 6045 S Kenwood Ave, Chicago, IL 60637
</div>
	</div>

  <script src="js/jquery.min.js"></script>
  <script src="js/jquery-migrate-3.0.1.min.js"></script>
  <script src="js/jquery.stellar.min.js"></script>
  <script src="js/aos.js"></script>
  <script src="js/main.js"></script>

  </body>
</html>
